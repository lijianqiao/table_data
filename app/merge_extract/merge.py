"""
@Author: li
@Email: lijianqiao2906@live.com
@FileName: merge.py
@DateTime: 2024-12-19
@Docs: æ•°æ®åˆå¹¶åº”ç”¨
"""

import polars as pl
import streamlit as st

from app.base.base_app import BaseApp
from app.components.column_selector import ColumnSelector
from app.components.data_preview import DataPreview
from app.components.error_handler import ErrorHandler
from app.components.export_panel import ExportPanel
from app.components.file_uploader import FileUploader
from app.handlers.data_processor import DataProcessor
from app.handlers.file_handler import FileHandler
from app.state.session_manager import SessionManager
from app.utils.file_validator import FileValidator
from app.utils.logger import log_function_calls, logger


class MergeApp(BaseApp):
    """æ•°æ®åˆå¹¶åº”ç”¨

    åˆå¹¶å¤šä¸ªæ•°æ®è¡¨ä¸ºä¸€ä¸ªç»Ÿä¸€çš„æ•°æ®è¡¨
    """

    @log_function_calls()
    def __init__(self):
        """åˆå§‹åŒ–åº”ç”¨"""
        logger.info("åˆå§‹åŒ–æ•°æ®åˆå¹¶åº”ç”¨")

        # ä½¿ç”¨å…¨å±€æœåŠ¡ç®¡ç†å™¨è·å–æœåŠ¡ï¼Œå¦‚æœä¸å¯ç”¨åˆ™åˆ›å»ºæœ¬åœ°å®ä¾‹
        try:
            from app.core.service_manager import ServiceManager

            self.file_validator = ServiceManager.get_service("file_validator")
            self.file_uploader = ServiceManager.get_service("file_uploader")
            self.file_handler = ServiceManager.get_service("file_handler")
            self.data_processor = ServiceManager.get_service("data_processor")
            logger.debug("ä½¿ç”¨å…¨å±€æœåŠ¡ç®¡ç†å™¨è·å–æœåŠ¡")

        except (RuntimeError, ValueError):
            # å…œåº•ï¼šåˆ›å»ºæœ¬åœ°æœåŠ¡å®ä¾‹
            logger.warning("å…¨å±€æœåŠ¡ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œåˆ›å»ºæœ¬åœ°æœåŠ¡å®ä¾‹")
            self.file_validator = FileValidator()
            self.file_uploader = FileUploader(self.file_validator)
            self.file_handler = FileHandler()
            self.data_processor = DataProcessor()

        logger.info("æ•°æ®åˆå¹¶åº”ç”¨åˆå§‹åŒ–å®Œæˆ")

    def get_name(self) -> str:
        """è·å–åº”ç”¨åç§°"""
        return "æ•°æ®åˆå¹¶"

    def get_description(self) -> str:
        """è·å–åº”ç”¨æè¿°"""
        return "åˆå¹¶å¤šä¸ªæ•°æ®è¡¨ä¸ºä¸€ä¸ªç»Ÿä¸€çš„æ•°æ®è¡¨"

    def validate_input(self, data: pl.DataFrame) -> bool:
        """éªŒè¯è¾“å…¥æ•°æ®

        Args:
            data: å¾…éªŒè¯çš„æ•°æ®

        Returns:
            éªŒè¯æ˜¯å¦é€šè¿‡
        """
        is_valid = data is not None and len(data) > 0
        logger.debug(
            f"è¾“å…¥æ•°æ®éªŒè¯: {'é€šè¿‡' if is_valid else 'å¤±è´¥'} | æ•°æ®è¡Œæ•°: {len(data) if data is not None else 0}"
        )
        return is_valid

    @log_function_calls()
    def render(self) -> None:
        """æ¸²æŸ“åº”ç”¨ç•Œé¢"""
        logger.info("å¼€å§‹æ¸²æŸ“æ•°æ®åˆå¹¶åº”ç”¨ç•Œé¢")

        st.header("ğŸ”— æ•°æ®åˆå¹¶å·¥å…·")
        st.markdown("å°†å¤šä¸ªæ•°æ®è¡¨åˆå¹¶ä¸ºä¸€ä¸ªç»Ÿä¸€çš„æ•°æ®è¡¨")

        # åˆ›å»ºæ ‡ç­¾é¡µ
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ æ–‡ä»¶ä¸Šä¼ ", "ğŸ“‹ æ•°æ®é¢„è§ˆ", "ğŸ¯ å­—æ®µé€‰æ‹©", "ğŸ“¤ å¯¼å‡ºæ•°æ®"])

        with tab1:
            self._render_file_upload_tab()

        with tab2:
            self._render_data_preview_tab()

        with tab3:
            self._render_column_selection_tab()

        with tab4:
            self._render_export_tab()

        logger.debug("æ•°æ®åˆå¹¶åº”ç”¨ç•Œé¢æ¸²æŸ“å®Œæˆ")

    @log_function_calls()
    def _render_file_upload_tab(self) -> None:
        """æ¸²æŸ“æ–‡ä»¶ä¸Šä¼ æ ‡ç­¾é¡µ"""
        logger.debug("æ¸²æŸ“æ–‡ä»¶ä¸Šä¼ æ ‡ç­¾é¡µ")

        st.subheader("ğŸ“ æ–‡ä»¶ä¸Šä¼ ")

        # æ·»åŠ åŠŸèƒ½è¯´æ˜
        st.markdown("""
        **æ•°æ®åˆå¹¶å·¥å…·è¯´æ˜ï¼š**
        - æ”¯æŒ CSVã€Excel æ ¼å¼ï¼Œå¯åŒæ—¶ä¸Šä¼ å¤šä¸ªæ–‡ä»¶
        - è¦æ±‚æ‰€æœ‰æ–‡ä»¶çš„å­—æ®µç»“æ„å®Œå…¨ä¸€è‡´
        - è‡ªåŠ¨æ·»åŠ "æ¥æº"åˆ—ï¼Œè®°å½•æ¯è¡Œæ•°æ®çš„æ¥æºæ–‡ä»¶
        - é€‚ç”¨äºéœ€è¦åˆå¹¶å¤šä¸ªç›¸åŒç»“æ„æ•°æ®è¡¨çš„åœºæ™¯
        """)

        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_files = self.file_uploader.render()

        if uploaded_files:
            logger.info(f"ç”¨æˆ·ä¸Šä¼ äº† {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            SessionManager.set_state("uploaded_files", uploaded_files)

            # å¤„ç†æ–‡ä»¶å¹¶åˆå¹¶æ•°æ®
            self._process_and_merge_files(uploaded_files)
        else:
            logger.debug("æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
            st.info("è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ•°æ®æ–‡ä»¶")

    @log_function_calls()
    def _process_and_merge_files(self, uploaded_files: list) -> None:
        """å¤„ç†å¹¶åˆå¹¶æ–‡ä»¶

        Args:
            uploaded_files: ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
        """
        logger.info(f"å¼€å§‹å¤„ç†å’Œåˆå¹¶æ–‡ä»¶ | æ–‡ä»¶æ•°é‡: {len(uploaded_files)}")

        try:
            with st.spinner("æ­£åœ¨è¯»å–å’Œåˆå¹¶æ–‡ä»¶..."):
                all_dataframes = []
                source_names = []

                # è¯»å–æ¯ä¸ªæ–‡ä»¶å¹¶å‡†å¤‡æ¥æºä¿¡æ¯
                for i, file in enumerate(uploaded_files):
                    logger.debug(f"å¤„ç†æ–‡ä»¶ {i + 1}/{len(uploaded_files)}: {file.name}")

                    try:
                        dfs = self.file_handler.read_file(file)

                        # æå–æ–‡ä»¶åä½œä¸ºæ¥æºæ ‡è¯†ï¼ˆå»æ‰æ‰©å±•åï¼‰
                        import os

                        source_name = os.path.splitext(file.name)[0]

                        # ä¸ºæ¯ä¸ªå·¥ä½œè¡¨æ·»åŠ æ¥æºä¿¡æ¯
                        for j, df in enumerate(dfs):
                            all_dataframes.append(df)
                            # å¦‚æœæœ‰å¤šä¸ªå·¥ä½œè¡¨ï¼Œæ·»åŠ å·¥ä½œè¡¨æ ‡è¯†
                            if len(dfs) > 1:
                                source_names.append(f"{source_name}_å·¥ä½œè¡¨{j + 1}")
                            else:
                                source_names.append(source_name)

                        logger.debug(f"æ–‡ä»¶ {file.name} è¯»å–æˆåŠŸï¼ŒåŒ…å« {len(dfs)} ä¸ªæ•°æ®è¡¨")

                    except Exception as e:
                        error_msg = f"æ–‡ä»¶ {file.name} è¯»å–å¤±è´¥: {str(e)}"
                        logger.error(error_msg)
                        ErrorHandler.show_error(error_msg)
                        continue

                if not all_dataframes:
                    error_msg = "æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ•°æ®"
                    logger.error(error_msg)
                    ErrorHandler.show_error(error_msg)
                    return

                # ä½¿ç”¨æ–°çš„åˆå¹¶æ–¹æ³•ï¼Œä¸“é—¨å¤„ç†å­—æ®µä¸€è‡´çš„åœºæ™¯
                logger.info(f"å¼€å§‹åˆå¹¶æ•°æ® | æ€»æ•°æ®è¡¨æ•°é‡: {len(all_dataframes)} | æ¥æºæ•°é‡: {len(source_names)}")
                merged_data = self.data_processor.merge_identical_dataframes(all_dataframes, source_names)

                # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                SessionManager.set_state("processed_data", merged_data)

                # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯å’Œæ¥æºç»Ÿè®¡
                success_msg = (
                    f"æ–‡ä»¶å¤„ç†å®Œæˆï¼åˆå¹¶åæ•°æ®: {len(merged_data)} è¡Œ x {len(merged_data.columns)} åˆ—ï¼ˆåŒ…å«æ¥æºåˆ—ï¼‰"
                )
                logger.info(success_msg)
                ErrorHandler.show_success(success_msg)

                # æ˜¾ç¤ºæ¥æºç»Ÿè®¡ä¿¡æ¯
                if "æ¥æº" in merged_data.columns:
                    source_stats = merged_data.group_by("æ¥æº").len().sort("len", descending=True)
                    st.subheader("ğŸ“Š æ•°æ®æ¥æºç»Ÿè®¡")
                    stats_data = []
                    for row in source_stats.iter_rows():
                        source, count = row
                        stats_data.append({"æ¥æºæ–‡ä»¶": source, "æ•°æ®è¡Œæ•°": count})

                    import polars as pl

                    stats_df = pl.DataFrame(stats_data)
                    st.dataframe(stats_df, use_container_width=True)

        except Exception as e:
            error_msg = f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}"
            logger.exception(error_msg)
            ErrorHandler.show_error("æ–‡ä»¶å¤„ç†å¤±è´¥", str(e))

    @log_function_calls()
    def _render_data_preview_tab(self) -> None:
        """æ¸²æŸ“æ•°æ®é¢„è§ˆæ ‡ç­¾é¡µ"""
        logger.debug("æ¸²æŸ“æ•°æ®é¢„è§ˆæ ‡ç­¾é¡µ")

        processed_data = SessionManager.get_state("processed_data")

        if processed_data is None:
            st.info("è¯·å…ˆåœ¨'æ–‡ä»¶ä¸Šä¼ 'æ ‡ç­¾é¡µä¸­ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶")
            logger.debug("æ²¡æœ‰å¯é¢„è§ˆçš„æ•°æ®")
            return

        logger.debug(f"æ˜¾ç¤ºæ•°æ®é¢„è§ˆ | è¡Œæ•°: {len(processed_data)} | åˆ—æ•°: {len(processed_data.columns)}")

        preview = DataPreview()
        st.subheader("ğŸ“Š åˆå¹¶ç»“æœé¢„è§ˆ")

        # æ•°æ®æ‘˜è¦
        with st.expander("ğŸ“Š æ•°æ®æ‘˜è¦", expanded=True):
            preview.render_summary(processed_data)

        # è¯¦ç»†æ•°æ®é¢„è§ˆ
        with st.expander("ğŸ“‹ è¯¦ç»†æ•°æ®é¢„è§ˆ", expanded=False):
            preview.render_sample_data(processed_data)

        # å­—æ®µè¯¦æƒ…
        with st.expander("ğŸ“Š å­—æ®µè¯¦æƒ…", expanded=False):
            preview.render_column_info(processed_data)

    @log_function_calls()
    def _render_column_selection_tab(self) -> None:
        """æ¸²æŸ“å­—æ®µé€‰æ‹©æ ‡ç­¾é¡µ"""
        logger.debug("æ¸²æŸ“å­—æ®µé€‰æ‹©æ ‡ç­¾é¡µ")

        processed_data = SessionManager.get_state("processed_data")

        if processed_data is None:
            st.info("è¯·å…ˆåœ¨'æ–‡ä»¶ä¸Šä¼ 'æ ‡ç­¾é¡µä¸­ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶")
            logger.debug("æ²¡æœ‰å¯é€‰æ‹©å­—æ®µçš„æ•°æ®")
            return

        logger.debug(f"æ˜¾ç¤ºå­—æ®µé€‰æ‹© | å¯é€‰å­—æ®µæ•°: {len(processed_data.columns)}")

        selector = ColumnSelector()
        selected_columns, is_confirmed = selector.render_with_preview(processed_data)

        # åªæœ‰åœ¨ç¡®è®¤åæ‰ä¿å­˜é€‰æ‹©çš„å­—æ®µ
        if is_confirmed and selected_columns:
            SessionManager.set_state("selected_columns", selected_columns)
            logger.info(f"ç”¨æˆ·ç¡®è®¤é€‰æ‹©äº† {len(selected_columns)} ä¸ªå­—æ®µ")

            # æ˜¾ç¤ºç¡®è®¤æˆåŠŸçš„æç¤º
            st.balloons()  # æ·»åŠ ä¸€ä¸ªå°çš„åº†ç¥æ•ˆæœ

        elif selected_columns and not is_confirmed:
            logger.debug(f"ç”¨æˆ·é€‰æ‹©äº† {len(selected_columns)} ä¸ªå­—æ®µä½†å°šæœªç¡®è®¤")
        else:
            logger.debug("ç”¨æˆ·æœªé€‰æ‹©ä»»ä½•å­—æ®µ")

    @log_function_calls()
    def _render_export_tab(self) -> None:
        """æ¸²æŸ“å¯¼å‡ºæ ‡ç­¾é¡µ"""
        logger.debug("æ¸²æŸ“å¯¼å‡ºæ ‡ç­¾é¡µ")

        processed_data = SessionManager.get_state("processed_data")
        selected_columns = SessionManager.get_state("selected_columns")

        if processed_data is None:
            st.info("è¯·å…ˆåœ¨'æ–‡ä»¶ä¸Šä¼ 'æ ‡ç­¾é¡µä¸­ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶")
            logger.debug("æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")
            return

        if not selected_columns:
            st.info("è¯·å…ˆåœ¨'å­—æ®µé€‰æ‹©'æ ‡ç­¾é¡µä¸­é€‰æ‹©è¦å¯¼å‡ºçš„å­—æ®µ")
            logger.debug("æ²¡æœ‰é€‰æ‹©è¦å¯¼å‡ºçš„å­—æ®µ")
            return

        logger.info(f"æ˜¾ç¤ºå¯¼å‡ºé¢æ¿ | æ•°æ®è¡Œæ•°: {len(processed_data)} | é€‰æ‹©å­—æ®µæ•°: {len(selected_columns)}")

        # æ˜¾ç¤ºå¯¼å‡ºé¢æ¿
        try:
            from app.core.service_manager import ServiceManager

            _ = ServiceManager.get_service("export_handler")
            logger.debug("ä½¿ç”¨å…¨å±€æœåŠ¡è·å–å¯¼å‡ºå¤„ç†å™¨")
        except (RuntimeError, ValueError):
            from app.handlers.export_handler import ExportHandler

            _ = ExportHandler()
            logger.debug("åˆ›å»ºæœ¬åœ°å¯¼å‡ºå¤„ç†å™¨å®ä¾‹")

        export_panel = ExportPanel()
        export_panel.render(processed_data, selected_columns)
